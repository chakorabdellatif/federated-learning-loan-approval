# ğŸ¦ SystÃ¨me d'Approbation de PrÃªts par Apprentissage FÃ©dÃ©rÃ©

## ğŸ“‹ Table des MatiÃ¨res
- [Vue d'ensemble](#-vue-densemble)
- [Architecture du SystÃ¨me](#-architecture-du-systÃ¨me)
- [Technologies UtilisÃ©es](#-technologies-utilisÃ©es)
- [Structure du Projet](#-structure-du-projet)
- [PrÃ©paration des DonnÃ©es](#-prÃ©paration-des-donnÃ©es)
- [Flux de Fonctionnement](#-flux-de-fonctionnement)
- [Installation et DÃ©marrage](#-installation-et-dÃ©marrage)
- [Tableaux de Bord et Monitoring](#-tableaux-de-bord-et-monitoring)
- [Avantages du SystÃ¨me](#-avantages-du-systÃ¨me)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente un **systÃ¨me d'apprentissage fÃ©dÃ©rÃ©** pour l'approbation de prÃªts bancaires, permettant Ã  trois banques de collaborer pour construire un modÃ¨le ML puissant tout en **prÃ©servant la confidentialitÃ©** de leurs donnÃ©es locales.

### CaractÃ©ristiques Principales

âœ… **ConfidentialitÃ© des DonnÃ©es** : Chaque banque conserve ses donnÃ©es localement  
âœ… **Apprentissage Collaboratif** : Les banques partagent uniquement les poids du modÃ¨le, pas les donnÃ©es  
âœ… **Traitement en Temps RÃ©el** : Streaming de transactions via Apache Kafka  
âœ… **RÃ©entraÃ®nement Automatique** : Mise Ã  jour du modÃ¨le toutes les heures  
âœ… **Monitoring Complet** : Grafana + Prometheus pour la supervision systÃ¨me  
âœ… **Visualisation Interactive** : Dashboard Streamlit pour les mÃ©triques ML  

### Dataset UtilisÃ©

**Source** : [Loan Approval Classification Dataset](https://www.kaggle.com/datasets/taweilo/loan-approval-classification-data)

**RÃ©partition** :
- ğŸ¦ **Banque 1** : 10,000 transactions historiques
- ğŸ¦ **Banque 2** : 10,000 transactions historiques  
- ğŸ¦ **Banque 3** : 10,000 transactions historiques
- ğŸ“¡ **Kafka (streaming)** : 15,000 transactions pour tests en temps rÃ©el

---

## ğŸ—ï¸ Architecture du SystÃ¨me

```mermaid
graph TB
    subgraph "Couche Client (Banques)"
        B1[ğŸ¦ Banque 1<br/>Dataset Local<br/>ModÃ¨le Local]
        B2[ğŸ¦ Banque 2<br/>Dataset Local<br/>ModÃ¨le Local]
        B3[ğŸ¦ Banque 3<br/>Dataset Local<br/>ModÃ¨le Local]
    end
    
    subgraph "Couche Serveur"
        FS[ğŸŒ Serveur FÃ©dÃ©rÃ©<br/>FastAPI<br/>FedAvg]
        GM[(ğŸ“¦ ModÃ¨le Global<br/>AgrÃ©gÃ©)]
    end
    
    subgraph "Streaming en Temps RÃ©el"
        K[ğŸ“¨ Apache Kafka<br/>3 Topics]
        P1[Producer 1]
        P2[Producer 2]
        P3[Producer 3]
    end
    
    subgraph "Monitoring & Visualisation"
        ST[ğŸ“Š Streamlit<br/>ML Metrics]
        GF[ğŸ“ˆ Grafana<br/>System Metrics]
        PM[ğŸ” Prometheus<br/>Data Source]
    end
    
    B1 -->|EntraÃ®nement Local| B1
    B2 -->|EntraÃ®nement Local| B2
    B3 -->|EntraÃ®nement Local| B3
    
    B1 -->|Soumet Poids| FS
    B2 -->|Soumet Poids| FS
    B3 -->|Soumet Poids| FS
    
    FS -->|AgrÃ©gation FedAvg| GM
    GM -->|TÃ©lÃ©charge ModÃ¨le| B1
    GM -->|TÃ©lÃ©charge ModÃ¨le| B2
    GM -->|TÃ©lÃ©charge ModÃ¨le| B3
    
    P1 -->|1 txn/s| K
    P2 -->|1.33 txn/s| K
    P3 -->|1 txn/s| K
    
    K -->|Stream| B1
    K -->|Stream| B2
    K -->|Stream| B3
    
    B1 -->|MÃ©triques| ST
    B2 -->|MÃ©triques| ST
    B3 -->|MÃ©triques| ST
    
    FS --> PM
    K --> PM
    PM --> GF
```

---

## ğŸ› ï¸ Technologies UtilisÃ©es

### Machine Learning
- **XGBoost** : ModÃ¨le de classification pour l'approbation de prÃªts
- **FedAvg** : Algorithme d'agrÃ©gation pour l'apprentissage fÃ©dÃ©rÃ©
- **Scikit-learn** : Ã‰valuation et mÃ©triques (AUC, F1, Precision, Recall)

### Backend & API
- **FastAPI** : Serveur fÃ©dÃ©rÃ© pour l'agrÃ©gation des modÃ¨les
- **Python 3.9+** : Langage principal

### Streaming & Messagerie
- **Apache Kafka** : Streaming de transactions en temps rÃ©el
- **Zookeeper** : Coordination Kafka

### Monitoring & Visualisation
- **Streamlit** : Dashboard interactif pour les mÃ©triques ML
- **Grafana** : Visualisation des mÃ©triques systÃ¨me
- **Prometheus** : Collection de mÃ©triques et monitoring

### Conteneurisation
- **Docker** : Conteneurisation de tous les services
- **Docker Compose** : Orchestration multi-conteneurs

---

## ğŸ“ Structure du Projet

```
federated-learning-loan-approval/
â”‚
â”œâ”€â”€ data/                               # DonnÃ©es bancaires partitionnÃ©es
â”‚   â”œâ”€â”€ bank1/
â”‚   â”‚   â””â”€â”€ bank1_dataset.csv          # 10k transactions (Banque 1)
â”‚   â”œâ”€â”€ bank2/
â”‚   â”‚   â””â”€â”€ bank2_dataset.csv          # 10k transactions (Banque 2)
â”‚   â”œâ”€â”€ bank3/
â”‚   â”‚   â””â”€â”€ bank3_dataset.csv          # 10k transactions (Banque 3)
â”‚   â””â”€â”€ kafka/
â”‚       â””â”€â”€ real_time_testing_dataset.csv  # 15k transactions (streaming)
â”‚
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ federated_server.py            # Serveur FastAPI avec FedAvg
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ clients/
â”‚   â”œâ”€â”€ bank_client.py                 # Client bancaire (train + predict)
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ kafka/
â”‚   â”œâ”€â”€ producer.py                    # Producteur de transactions Kafka
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ dashboards/
â”‚   â”œâ”€â”€ streamlit_app.py               # Dashboard interactif Streamlit
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .streamlit/
â”‚       â””â”€â”€ config.toml                
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile.server              # Image serveur fÃ©dÃ©rÃ©
â”‚   â”œâ”€â”€ Dockerfile.client              # Image client bancaire
â”‚   â”œâ”€â”€ Dockerfile.kafka               # Image producteur Kafka
â”‚   â””â”€â”€ Dockerfile.streamlit           # Image dashboard Streamlit
â”‚
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml                 # Configuration Prometheus
â”‚   â”œâ”€â”€ kafka.yml                      # MÃ©triques JMX Kafka
â”‚   â””â”€â”€ jmx_prometheus_javaagent-1.5.0.jar  
â”‚
â”œâ”€â”€ models/                            # CrÃ©Ã© automatiquement
â”‚   â”œâ”€â”€ global/                        # ModÃ¨les globaux agrÃ©gÃ©s
â”‚   â””â”€â”€ local/                         # ModÃ¨les locaux par banque
â”‚       â”œâ”€â”€ bank_1/
â”‚       â”œâ”€â”€ bank_2/
â”‚       â””â”€â”€ bank_3/
â”‚
â”œâ”€â”€ logs/                              # CrÃ©Ã© automatiquement
â”‚   â”œâ”€â”€ server/                        # Logs du serveur fÃ©dÃ©rÃ©
â”‚   â”œâ”€â”€ bank1/                         # Logs + mÃ©triques Banque 1
â”‚   â”œâ”€â”€ bank2/                         # Logs + mÃ©triques Banque 2
â”‚   â””â”€â”€ bank3/                         # Logs + mÃ©triques Banque 3
â”‚
â”œâ”€â”€ docker-compose.yml                 # Orchestration complÃ¨te
â”œâ”€â”€ models_testing.ipynb               # Analyse comparative des modÃ¨les
â””â”€â”€ README.md                          # Ce fichier
```

---

## ğŸ“Š PrÃ©paration des DonnÃ©es

Le notebook `models_testing.ipynb` contient l'analyse prÃ©liminaire et la prÃ©paration des donnÃ©es :

### Contenu du Notebook
- **Exploration des donnÃ©es** : Analyse statistique et visualisations
- **Partitionnement** : Division du dataset en 4 chunks (3 pour les banques + 1 pour Kafka)
- **Comparaison de modÃ¨les** : RÃ©gression Logistique vs XGBoost
- **SÃ©lection du modÃ¨le optimal** : XGBoost choisi pour ses performances supÃ©rieures
- **Ã‰valuation des mÃ©triques** : AUC, F1-Score, Precision, Recall

> ğŸ“ **Note** : Les datasets sont dÃ©jÃ  prÃ©parÃ©s et inclus dans le dÃ©pÃ´t. Le notebook est fourni uniquement Ã  titre de rÃ©fÃ©rence pour comprendre le processus de prÃ©paration.

---

## ğŸ”„ Flux de Fonctionnement

### Phase 1ï¸âƒ£ : EntraÃ®nement Initial (Round 0)

```mermaid
sequenceDiagram
    participant B1 as ğŸ¦ Banque 1
    participant B2 as ğŸ¦ Banque 2
    participant B3 as ğŸ¦ Banque 3
    participant FS as ğŸŒ Serveur FÃ©dÃ©rÃ©
    
    Note over B1,B3: Chaque banque charge son dataset local
    
    B1->>B1: EntraÃ®nement XGBoost sur 10k transactions
    B2->>B2: EntraÃ®nement XGBoost sur 10k transactions
    B3->>B3: EntraÃ®nement XGBoost sur 10k transactions
    
    Note over B1,B3: Soumission des poids (pas les donnÃ©es!)
    
    B1->>FS: POST /submit_model (poids modÃ¨le)
    B2->>FS: POST /submit_model (poids modÃ¨le)
    B3->>FS: POST /submit_model (poids modÃ¨le)
    
    Note over FS: AgrÃ©gation FedAvg (3/3 modÃ¨les reÃ§us)
    FS->>FS: Calcul du modÃ¨le global agrÃ©gÃ©
    
    B1->>FS: GET /get_global_model
    FS->>B1: ModÃ¨le global (Round 1)
    
    B2->>FS: GET /get_global_model
    FS->>B2: ModÃ¨le global (Round 1)
    
    B3->>FS: GET /get_global_model
    FS->>B3: ModÃ¨le global (Round 1)
    
    Note over B1,B3: PrÃªts Ã  traiter les transactions en temps rÃ©el!
```

### Phase 2ï¸âƒ£ : Streaming et PrÃ©dictions en Temps RÃ©el

```mermaid
sequenceDiagram
    participant P1 as ğŸ“¨ Producer 1
    participant P2 as ğŸ“¨ Producer 2
    participant P3 as ğŸ“¨ Producer 3
    participant K as ğŸ“¡ Kafka
    participant B1 as ğŸ¦ Banque 1
    participant B2 as ğŸ¦ Banque 2
    participant B3 as ğŸ¦ Banque 3
    
    loop Toutes les secondes
        P1->>K: Transaction (bank1_txn topic)
        P2->>K: Transaction (bank2_txn topic)
        P3->>K: Transaction (bank3_txn topic)
    end
    
    K->>B1: Stream transaction
    B1->>B1: PrÃ©diction avec modÃ¨le global
    B1->>B1: APPROUVÃ‰ / REFUSÃ‰
    
    K->>B2: Stream transaction
    B2->>B2: PrÃ©diction avec modÃ¨le global
    B2->>B2: APPROUVÃ‰ / REFUSÃ‰
    
    K->>B3: Stream transaction
    B3->>B3: PrÃ©diction avec modÃ¨le global
    B3->>B3: APPROUVÃ‰ / REFUSÃ‰
    
    Note over B1,B3: AprÃ¨s 100 transactions par banque
    
    B1->>B1: Ajout au dataset local (batch)
    B2->>B2: Ajout au dataset local (batch)
    B3->>B3: Ajout au dataset local (batch)
```

### Phase 3ï¸âƒ£ : RÃ©entraÃ®nement Automatique (Toutes les heures)

```mermaid
sequenceDiagram
    participant B1 as ğŸ¦ Banque 1
    participant B2 as ğŸ¦ Banque 2
    participant B3 as ğŸ¦ Banque 3
    participant FS as ğŸŒ Serveur FÃ©dÃ©rÃ©
    
    Note over B1,B3: â° Timer 1h Ã©coulÃ©
    
    B1->>B1: RÃ©entraÃ®nement sur dataset Ã©largi
    B2->>B2: RÃ©entraÃ®nement sur dataset Ã©largi
    B3->>B3: RÃ©entraÃ®nement sur dataset Ã©largi
    
    B1->>FS: POST /submit_model (nouveau poids)
    B2->>FS: POST /submit_model (nouveau poids)
    B3->>FS: POST /submit_model (nouveau poids)
    
    Note over FS: AgrÃ©gation manuelle/programmÃ©e
    FS->>FS: Calcul nouveau modÃ¨le global
    
    B1->>FS: GET /get_global_model
    FS->>B1: ModÃ¨le global (Round N+1)
    
    B2->>FS: GET /get_global_model
    FS->>B2: ModÃ¨le global (Round N+1)
    
    B3->>FS: GET /get_global_model
    FS->>B3: ModÃ¨le global (Round N+1)
    
    Note over B1,B3: Continuer le streaming avec le modÃ¨le amÃ©liorÃ©
```

---

## ğŸš€ Installation et DÃ©marrage

### PrÃ©requis

- **Docker** >= 20.10
- **Docker Compose** >= 2.0
- **Git**
- Au moins **8 GB RAM** disponible
- Au moins **10 GB** d'espace disque

### Installation

```bash
# 1. Cloner le dÃ©pÃ´t
git clone https://github.com/chakorabdellatif/federated-learning-loan-approval.git
cd federated-learning-loan-approval

# 2. VÃ©rifier la structure des donnÃ©es
ls data/bank1/bank1_dataset.csv
ls data/bank2/bank2_dataset.csv
ls data/bank3/bank3_dataset.csv
ls data/kafka/real_time_testing_dataset.csv

# 3. DÃ©marrer tous les services
docker-compose up -d

# 4. VÃ©rifier le statut des conteneurs
docker-compose ps
```

### VÃ©rification du DÃ©marrage

```bash
# VÃ©rifier les logs du serveur fÃ©dÃ©rÃ©
docker logs federated-server -f

# VÃ©rifier les logs d'une banque
docker logs bank1-client -f

# VÃ©rifier Kafka
docker logs kafka -f
```

### Ordre de DÃ©marrage Automatique

1. **Zookeeper** â†’ **Kafka** (coordination)
2. **Serveur FÃ©dÃ©rÃ©** (agrÃ©gation)
3. **Clients Bancaires** (entraÃ®nement initial â†’ Round 0)
4. **Producteurs Kafka** (attendent la fin du Round 0)
5. **Streamlit & Grafana** (dashboards)

> â³ **Le dÃ©marrage complet prend ~2-3 minutes**

---

## ğŸ“Š Tableaux de Bord et Monitoring

### 1. Streamlit Dashboard (Port 8501)

AccÃ¨s : [http://localhost:8501](http://localhost:8501)

#### ğŸ“ˆ Comparaison des ModÃ¨les

![Comparaison des MÃ©triques ML](placeholder_streamlit_models.png)
<img width="2164" height="1366" alt="Screenshot 2025-12-22 171319" src="https://github.com/user-attachments/assets/a8d9f224-4ca3-4e46-ad7c-ed7b9bb727f3" />

**MÃ©triques affichÃ©es par banque** :
- **Accuracy** : PrÃ©cision globale du modÃ¨le
- **AUC-ROC** : Aire sous la courbe ROC
- **F1-Score** : Moyenne harmonique de prÃ©cision/rappel
- **Precision** : Taux de vrais positifs parmi les prÃ©dictions positives
- **Recall** : Taux de vrais positifs dÃ©tectÃ©s
- **Nombre de prÃ©dictions**
- **Taux d'approbation/refus**

#### ğŸ¬ Streaming Kafka en Temps RÃ©el

![Visualisation Kafka Streaming](placeholder_streamlit_kafka.png)
<img width="2192" height="1199" alt="Screenshot 2025-12-22 171410" src="https://github.com/user-attachments/assets/b6f32c42-e526-4799-ba2d-7ee92eecaf08" />
<img width="2155" height="1372" alt="Screenshot 2025-12-22 171427" src="https://github.com/user-attachments/assets/8781431b-3e64-4734-96a6-18dfc7bb817f" />

**Informations affichÃ©es** :
- Volume de transactions par seconde
- RÃ©partition par banque
- Statut des topics Kafka
- Latence du streaming
- Taux d'approbation en temps rÃ©el

---

### 2. Grafana (Port 3000)

AccÃ¨s : [http://localhost:3000](http://localhost:3000)  
**Identifiants** : `admin` / `admin`

#### ğŸ“Š Dashboard 1 : Utilisation des Ressources

![Ressources SystÃ¨me](placeholder_grafana_resources.png)
<img width="2123" height="1172" alt="Screenshot 2025-12-22 171502" src="https://github.com/user-attachments/assets/cf9b23e0-c2bb-4622-b05a-c7e772d556a9" />

**Panels disponibles** :
- CPU usage par conteneur
- MÃ©moire RAM utilisÃ©e/disponible
- I/O Disque (lecture/Ã©criture)
- RÃ©seau (trafic entrant/sortant)
- Nombre de conteneurs actifs

---

#### ğŸŒ Dashboard 2 : Serveur FÃ©dÃ©rÃ©

![Serveur FÃ©dÃ©rÃ©](placeholder_grafana_server.png)
<img width="2133" height="1298" alt="Screenshot 2025-12-22 173057" src="https://github.com/user-attachments/assets/8530a867-ac6c-4119-a6a1-088cfd80c543" />

**Panels disponibles** :
- Nombre de rounds d'entraÃ®nement
- ModÃ¨les reÃ§us par round
- Temps d'agrÃ©gation
- RequÃªtes API par endpoint
- Nombre de clients enregistrÃ©s
- ModÃ¨les sauvegardÃ©s (global/local)

---

### 3. Prometheus (Port 9090)
Grafana's data source
AccÃ¨s : [http://localhost:9090](http://localhost:9090)


---

## âœ¨ Avantages du SystÃ¨me

### ğŸ”„ Persistance et RÃ©silience

#### âœ… RedÃ©marrage Intelligent
- **Les modÃ¨les sont sauvegardÃ©s sur disque** : Le serveur fÃ©dÃ©rÃ© charge automatiquement le dernier modÃ¨le global
- **Pas de rÃ©entraÃ®nement depuis zÃ©ro** : Les banques tÃ©lÃ©chargent le modÃ¨le existant et reprennent le streaming
- **ContinuitÃ© du service** : ArrÃªter/redÃ©marrer l'application ne fait pas perdre les progrÃ¨s

```bash
# Exemple : RedÃ©marrer l'application
docker-compose down
docker-compose up -d

# âœ… Le systÃ¨me reprend au Round N (pas au Round 0!)
# âœ… Les datasets des banques contiennent toutes les transactions passÃ©es
# âœ… Le streaming Kafka continue normalement
```

#### ğŸ—„ï¸ Stockage StructurÃ©
```
models/
â”œâ”€â”€ global/
â”‚   â”œâ”€â”€ latest.json          # â† Toujours le dernier modÃ¨le
â”‚   â”œâ”€â”€ round_1.json
â”‚   â”œâ”€â”€ round_2.json
â”‚   â””â”€â”€ round_N.json
â””â”€â”€ local/
    â”œâ”€â”€ bank_1/
    â”‚   â”œâ”€â”€ round_1.json
    â”‚   â””â”€â”€ round_N.json
    â”œâ”€â”€ bank_2/
    â””â”€â”€ bank_3/
```

---

### ğŸ”’ ConfidentialitÃ© des DonnÃ©es

- **Les donnÃ©es restent locales** : Aucune banque ne voit les donnÃ©es d'une autre
- **Seuls les poids sont partagÃ©s** : Le serveur ne reÃ§oit que les paramÃ¨tres du modÃ¨le
- **ConformitÃ© rÃ©glementaire** : Respecte le RGPD et autres lois sur la protection des donnÃ©es

---

### ğŸ“ˆ AmÃ©lioration Continue

- **Apprentissage incrÃ©mental** : Le modÃ¨le s'amÃ©liore avec chaque round
- **Adaptation aux nouvelles donnÃ©es** : RÃ©entraÃ®nement automatique toutes les heures
- **BÃ©nÃ©fice mutuel** : Toutes les banques profitent des donnÃ©es agrÃ©gÃ©es sans les partager

---

### âš¡ Performance

- **Traitement en temps rÃ©el** : PrÃ©dictions instantanÃ©es via Kafka streaming
- **ScalabilitÃ©** : Architecture conteneurisÃ©e facilement extensible
- **Monitoring complet** : DÃ©tection proactive des problÃ¨mes de performance

---

### ğŸ› ï¸ FacilitÃ© d'utilisation

- **DÃ©ploiement en une commande** : `docker-compose up -d`
- **Dashboards intuitifs** : Streamlit + Grafana pour la visualisation
- **Configuration flexible** : Variables d'environnement ajustables
---
## ğŸ“š Ressources SupplÃ©mentaires

- **Dataset Kaggle** : [Loan Approval Classification](https://www.kaggle.com/datasets/taweilo/loan-approval-classification-data)
- **XGBoost Documentation** : [https://xgboost.readthedocs.io](https://xgboost.readthedocs.io)
- **FastAPI Docs** : [https://fastapi.tiangolo.com](https://fastapi.tiangolo.com)
- **Apache Kafka Guide** : [https://kafka.apache.org/documentation](https://kafka.apache.org/documentation)
- **Federated Learning Paper** : [Communication-Efficient Learning (McMahan et al.)](https://arxiv.org/abs/1602.05629)

---

## ğŸ“§ Contact

Pour toute question ou suggestion, n'hÃ©sitez pas Ã  ouvrir une issue sur GitHub.

---

**DÃ©veloppÃ© avec â¤ï¸ pour dÃ©montrer la puissance de l'apprentissage fÃ©dÃ©rÃ© dans le secteur bancaire**
